{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "* Students should be able to assess the structure and cleanliness of their dataset, including size and shape of data, number of variables of each type \n",
    "* Students should be able to describe their findings, translate results from code to text using Markdown comments in the Jupyter Notebook, and summarize their thought process in a narrative\n",
    "* Students should be able to modify the raw data to prepare a clean data set -- including copying data, removing or replacing missing and incoherent data, dropping columns, removing duplicates in Pandas and Jupyter -- and explain and justify their decisions in markdown in their Jupyter notebook\n",
    "* Students should be able to assess whether their data is “Tidy” and identify appropriate steps and write and  execute code to arrange it into a tidy format - including merging, reshaping, subsetting, grouping, sorting, making appropriate new columns  - and explain and justify their decisions in markdown in their Jupyter notebook\n",
    "* Students should be able to identify several relevant summary measures, illustrate data using appropriate plots, and explain and justify their decisions in markdown in their Jupyter notebook\n",
    "* Student should assess the summaries and plots and appraise the need for repeated or further analysis, and justify decisions in markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe findings, translate results into Markdown text\n",
    " This is more of an overarching goal that should be woven in through the lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the notebook\n",
    "\n",
    "## About Libraries in Python\n",
    "\n",
    "A library in Python contains a set of tools (called functions) that perform tasks on our data. Importing a library is like getting a piece of lab equipment out of a storage locker and setting it up on the bench for use in a project. Once a library is imported, it can be used or called to perform many tasks.\n",
    "\n",
    "## \n",
    "\n",
    "## The Pandas Library\n",
    "\n",
    "One of the best options for working with tabular data in Python is to use the Python Data Analysis Library (a.k.a. Pandas). The Pandas library provides data structures, produces high quality plots with matplotlib and integrates nicely with other libraries that use NumPy (which is another Python library) arrays.\n",
    "\n",
    "Python doesn’t load all of the libraries available to it by default. We have to add an import statement to our code in order to use library functions. To import a library, we use the syntax `import libraryName`. If we want to give the library a nickname to shorten the command, we can add `as nickNameHere`. An example of importing the pandas library using the common nickname pd is below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time we call a function that’s in a library, we use the syntax `LibraryName.FunctionName`. Adding the library name with a `.` before the function name tells Python where to find the function. In the example above, we have imported Pandas as `pd`. This means we don’t have to type out pandas each time we call a Pandas function.\n",
    "\n",
    "We will begin by locating and reading our data which are in a table format. We can use Pandas’ `read_table` function to pull the file directly into a DataFrame.\n",
    "\n",
    "# Getting data into the notebook\n",
    "\n",
    "## What’s a DataFrame?\n",
    "A DataFrame is a 2-dimensional data structure that can store data of different types (including characters, integers, floating point values, factors and more) in columns. It is similar to a spreadsheet or an SQL table or the data.frame in R. A DataFrame always has an index (0-based). An index refers to the position of an element in the data structure.\n",
    "\n",
    "Note that we use `pd.read_table`, not just `read_table` or `pandas.read_table`, because we imported pandas as pd.\n",
    "\n",
    "The columns in the data set are separated by a TAB. We need to tell the `read_table` function in Pandas that that is the case with `sep = ‘\\t’`.\n",
    "\n",
    "The first thing to do when loading data into the notebook is to actually look at it.  How many rows and columns are there?  What types of variables are in it and what values can they take?\n",
    "\n",
    "There are usually too many rows to print to the screen.  By default, when you type the name of the dataframe and run a cell, Pandas knows not to print the whole thing.  Instead, you will see the first and last few rows with dots in between.  A neater way to view a preview of the dataset is the `head()` method.  Calling `dataset.head()` will displace the first 5 rows of the data.  You can specify how many rows you want to see as an argument, like `dataset.head(10)`.  The `tail()` method does the same with the last rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-dd0748aafa36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://raw.githubusercontent.com/Reproducible-Science-Curriculum/data-exploration-RR-Jupyter/master/gapminderDataFiveYear_dirty.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgapminder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgapminder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    299\u001b[0m     filepath_or_buffer, _, compression = get_filepath_or_buffer(\n\u001b[1;32m    300\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         compression=kwds.get('compression', None))\n\u001b[0m\u001b[1;32m    302\u001b[0m     kwds['compression'] = (inferred_compression if compression == 'infer'\n\u001b[1;32m    303\u001b[0m                            else compression)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_urlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'infer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Content-Encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 579\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/Reproducible-Science-Curriculum/data-exploration-RR-Jupyter/master/gapminderDataFiveYear_dirty.txt\"\n",
    "gapminder = pd.read_table(url, sep = \"\\t\")\n",
    "gapminder.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess the structure and cleanliness\n",
    "\n",
    "\n",
    "## How many rows and columns are in the data?\n",
    "We often want to know how many rows and columns are in the data  --  we want to know what is called the \"shape\" attribute of the data frame. Pandas has a convenient way for getting that information by using the `DataFrame.shape` (using DataFrame as a generic name for a, well, data frame). This returns a tuple (values separated by commas) representing the dimensions of the DataFrame (rows, columns).<p>\n",
    "To get the shape of the gapminder data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gapminder.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `info()` method gives a few useful pieces of information, including the shape of the dataframe, the variable type of each column, and the amount of memory stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gapminder.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `describe()` method will take the numeric columns and give a summary of their values. This is useful for getting a sense of the ranges of values and seeing if there are any unusual or suspicious numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gapminder.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "describe() just blindly looks at all numeric variables. But we wouldn't actually want to take the mean year. Let's pull out only the correct columns.  This is a preview of selection columns of the data; we'll talk more about how to do it later in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gapminder[['pop', 'life Exp', 'gdpPercap']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command value_counts() gives you a first global idea of your categorical data such as strings. In this case that is the column ‘Region’.\n",
    "The table reveals some problems. The data set covers 12 years, so each ‘region’ should appear 12 times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(gapminder['region'].unique())) # How many unique regions are in the data?\n",
    "gapminder['region'].value_counts() # How many times does each unique region occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also see inconsistencies (string variables are very susceptible to those), for instance:\n",
    "\n",
    "Asia_china\tvs. Asia_China\n",
    "\n",
    "Another type of problem is the various names of Congo. In order to analyze this dataset appropriately we need to take care of these issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify the dataset -- cleaning\n",
    "\n",
    "Skills to illustrate\n",
    "* Make a copy of the data\n",
    "in place vs. not\n",
    "pandas.DataFrame.copy() - make a copy of data frame\n",
    "* Assigning to new variable/df names \n",
    "* Dealing with missing data\n",
    "Pros and cons of dropping NAs and inconsistent data\n",
    "* Dealing with incoherent data (NA, na, N/A, n/a, ND, not done, XXXX) misspellings, etc\n",
    "Regex, data transformation to address inconsistency (fill_na)\n",
    "* dropping columns `df.drop()`:\n",
    "_In many instances, data sets may include variables that might not be relevant \n",
    "or interesting for the intended data exploration or downstream analysis. After\n",
    "an initial examination of the data, it's generally useful to remove from the \n",
    "data set those columns that correspond to irrelevant variables. Whenever \n",
    "removing variables, it is good practice to note exactly why such columns are\n",
    "being dropped._\n",
    "* Removing duplicates\n",
    "df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "If you find that your data set contains missing data, pandas allows you to either remove all instances will null data or replace them with a particular value.\n",
    "\n",
    "`df = df.dropna()` drops rows with any column having NA/null data\n",
    "`df = df.fillna(value)` %replace all NA/null data with value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gapminder = gapminder.dropna()\n",
    "gapminder.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling (Unwanted) Repetitive Data\n",
    "You can identify which observations are duplicates.\n",
    "The call `df.duplicated()` will return boolean values for each row in the DataFrame telling you whether or not a row is repetitive.\n",
    "\n",
    "In cases where you don’t want repetitive values (we wouldn’t--we only want each country to be represented once for every relevant year), you can easily drop such duplicate rows with the call `df.drop_duplicates()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gapminder.duplicated().head() #shows we have a repetition in the first 5 rows\n",
    "\n",
    "gapminder = gapminder.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 1704 rows, but our indexes are off. We can reset our indices easily with the call reset_index(drop=True).\n",
    "Remember, Python is 0-indexed so our indices will be valued 0-1703."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gapminder = gapminder.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Handling Inconsistent Data\n",
    "\n",
    "The `region` column is a bit too messy for what we'd like to do.\n",
    "The `value_counts()` operation above revealed some issues.\n",
    "\n",
    "### String manipulations\n",
    "\n",
    "Very common problems with string variables are  lingering white space and upper case vs. lower case.\n",
    "The following three commands remove all such trailing spaces (left and right) and put everything in lowercase. If you prefer, the three commands can be written in one single line (concept: chaining). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gapminder['region'] = gapminder['region'].str.lstrip() # Strip white space on left\n",
    "gapminder['region'] = gapminder['region'].str.rstrip() # Strip white space on right\n",
    "gapminder['region'] = gapminder['region'].str.lower() # Convert to lowercase\n",
    "gapminder['region'].value_counts() # How many times does each unique region occur?\n",
    "\n",
    "# We could have done this in one line!\n",
    "# gapminder['region'] = gapminder['region'].str.lstrip().str.rstrip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regex + replace()\n",
    "**Note: In code we need to uncomment correct regex of congo**\n",
    "A regular expression, aka regex, is a sequence of characters that define a search pattern. In a regular expression, the symbol “*” matches the preceding character 0 or more times, whereas “+” matches the preceding character 1 or more times. “.” matches any single character. Writing “x|y” means to match either ‘x’ or ‘y’.\n",
    "\n",
    "For more regex shortcuts (cheatsheet): https://www.shortcutfoo.com/app/dojos/regex/cheatsheet\n",
    "\n",
    "Pandas allows you to use regex in its replace() function -- when a regex term is found in an element, the element is then replaced with the specified replacement term. In order for it to appropriately correct elements, both regex and inplace variables need to be set to True (as their defaults are false). This ensures that the initial input string is read as a regular expression and that the elements will be modified in place.\n",
    "\n",
    "For more documentation on the replace method: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.replace.html\n",
    "\n",
    "Here's an incorrect regex example: we create a temporary DataFrame in which a regex pulls all values that contain the term “congo”. Unfortunately, this creates 24 instances of the Democratic Republic of the Congo -- this is an error in our cleaning! We can revert back to the non-temporary DataFrame and correctly modify our regex to isolate only the Democratic Republic instances (as opposed to including the Republic as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This gives a problem -- 24 values of the congo!\n",
    "temp = gapminder['region'].replace(\".*congo.*\", \"africa_dem rep congo\", regex=True)\n",
    "temp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What happened? This shows all the rows that have congo in the name.\n",
    "gapminder[gapminder[\"region\"].str.contains('congo')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regex to fix the Congo...\n",
    "\n",
    "As noted above, regular expressions (often simply \"regex\") provide a powerful \n",
    "tool for fixing errors that arise in strings. In order to correctly label the \n",
    "two different countries that include the word \"congo\", we need to design and\n",
    "use (via `pd.df.replace()`) a regex that correctly differentiates between the\n",
    "two countries.\n",
    "\n",
    "Recall that the \".\" is the wildcard (matching any single character); combining \n",
    "this with \"*\" allows us to match any number of single characters an unspecified \n",
    "number of times. By combining these characters with substrings corresponding to\n",
    "variations in the naming of the Democratic Republic of the Congo, we can\n",
    "correctly normalize the name.\n",
    "\n",
    "If you feel that the use of regex is not particularly straightforward, you are\n",
    "correct -- appropriately using these tools takes a great deal of time to master.\n",
    "When designing regex for these sorts of tasks, you might find the following\n",
    "prototyper helpful: https://regex101.com/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gapminder['region'].replace(\".*congo, dem.*\", \"africa_dem rep congo\", regex=True, inplace=True)\n",
    "gapminder['region'].replace(\".*_democratic republic of the congo\", \"africa_dem rep congo\", regex=True, inplace=True)\n",
    "gapminder['region'].value_counts() # Now it's fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (regex):\n",
    "\n",
    "Now that we've taken a close look at how to properly design and use regex to\n",
    "clean string entries in our data, let's try to normalize the naming of a few\n",
    "other countries. Using the pandas code we constructed above as a template,\n",
    "construct similar code (using `pd.df.replace()`) to set the naming of the Ivory\n",
    "Coast and Canada to \"africa_cote d'ivoire\" and \"americas_canada\", respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gapminder['region'].replace(\".*ivore.*\", \"africa_cote d'ivoire\", regex=True, inplace=True)\n",
    "gapminder['region'].replace(\"^_canada\", \"americas_canada\", regex=True, inplace=True)\n",
    "gapminder['region'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy data\n",
    "\n",
    "Having what is called a _Tidy_ data set can make cleaning your data much easier. Two of the important aspects of Tidy data are:\n",
    "* every variable has its own column\n",
    "* every observation has its own row\n",
    "\n",
    "(there are other aspects of Tidy data, here is a good blog post about Tidy data in Python: http://www.jeannicholashould.com/tidy-data-in-python.html)\n",
    "\n",
    "Currently the dataset has a single column for continent and country (the ‘region’ column). We can split that column into two, by using the underscore that separates continent from country.\n",
    "We can create a new column in the DataFrame by naming it before the = sign:\n",
    "`gapminder[‘country’] = `\n",
    "\n",
    "The following commands use the function split() to split the string at the underscore (the first argument), which results in a list of two elements: before and after the \\_. The second argument tells split() that the split should take place only at the first occurrence of the underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gapminder['country']=gapminder['region'].str.split('_', 1).str[1]\n",
    "gapminder['continent']=gapminder['region'].str.split('_', 1).str[0]\n",
    "gapminder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing and renaming columns\n",
    "\n",
    "We have now added the columns ‘country’ and ‘continent,’ but we still have the old ‘region’ column as well. In order to remove that column we use the drop() command. The first argument of the drop() command is the name of the element to be dropped. The second argument is the *axis* number: 0 for row, 1 for column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gapminder = gapminder.drop('region', 1)\n",
    "gapminder.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it is a good idea to look critically at your column names. Use lowercase for all column names to avoid confusing ‘gdppercap’ with ‘gdpPercap,’ or ‘GDPpercap.’ Avoid spaces in column names to simplify manipulating your data - look out for lingering white space at the beginning or end of your column names. The following code turns all column names to lowercase. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gapminder.columns = gapminder.columns.str.lower()\n",
    "gapminder.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to remove the space from the ‘life exp’ column name. We can do that with Pandas rename  command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gapminder = gapminder.rename(columns={'life exp' : 'lifeexp'})\n",
    "gapminder.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data structure -- tidy data\n",
    "\n",
    "* Merging datasets,\n",
    "Pandas - merge()[left, right, inner, outer], concat()\n",
    "* Subsetting data\n",
    "0) refer back to the way we selected columns in .describe() above\n",
    "1) Indexing - numerically(zero indexing) vs by names, boolean indices, \n",
    "2) Slicing - base python and/or pandas\n",
    "3) List comprehensions\n",
    "* Grouping data, Indexing DataFrames\n",
    "df.groupby(by=\"col\")\n",
    "* Sorting data\n",
    "df.sort_values()\n",
    "df.sort_index()\n",
    "\n",
    "Ideas: subset by continent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencing objects vs copying objects\n",
    "Suppose you take a subset of your data and store it in a new variable, like `gapminder_early = gapminder[gapminder['year'] < 1970]`.  Doing this does not actually create a new object. Instead, you have just given a name to that subset of the original data: gapminder_early points to those rows of gapminder.  Any changes you make to the new dataframe gapminder_early will appear in the corresponding rows of gapminder too.  \n",
    "\n",
    "Often, you want to leave the original data untouched.  To avoid this problem, you can make a copy of your data before operating on a subset of the data.  This will ensure that one version of the original data is preserved.  For instance:\n",
    "\n",
    "<font color='red'>**TO DO:** this example doesn't actually illustrate the problem :(</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gapminder_copy = gapminder.copy()\n",
    "gapminder_early = gapminder_copy[gapminder_copy['year'] < 1970]\n",
    "gapminder_early['pop'] = 0\n",
    "#print(gapminder_copy[gapminder_copy['year'] < 1970].head())\n",
    "#print(gapminder[gapminder['year'] < 1970].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize and plot\n",
    "\n",
    "Summaries (but can’t *say* statistics…)\n",
    "* Sort data\n",
    "* Can make note about using numpy functions, dif between dataframe and array\n",
    "Good Plots for the data/variable type\n",
    "\n",
    "\n",
    "\n",
    "Plots \n",
    "* of subsets, \n",
    "* single variables\n",
    "* pairs of variables\n",
    "* Matplotlib syntax (w/ seaborn for defaults (prettier, package also good for more analysis later...))\n",
    "\n",
    "Exploring is often iterative - summarize, plot, summarize, plot, etc. - sometimes it branches…\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
